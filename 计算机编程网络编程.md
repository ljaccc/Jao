# 死锁处理方式

- 预防死锁
- 避免死锁
- 检测死锁
- 解除死锁：
  - 剥夺资源 从其他进程剥夺足够数量的资源给死锁进程
  - 撤销进程
  
# 内存管理 
 
## 内存管理方式

- 块式管理
- 页式管理
- 段式管理
- 段页式管理（最常用）
- 虚拟地址 -> 逻辑地址（段表：标识段+段内偏移量） -> 线性地址（页表）
 -> 物理地址

### 虚拟内存置换方式
- OPT(Optimal Page Replacement)策略（最佳置换算法） 选择置换下次访问距当前时间最长的那些页。
- LRU(Least Recently Used)策略（最近最少使用算法（最常采用）） 置换内存中上次使用距当前最远的页。每次访问更新时间戳。
- FIFO(First In, First Out)策略（先进先出算法） 把分配给进程的页框视为一个循环缓冲区，按循环方式移动页。一部分程序或数据使用频率高，不停换入换出会增加系统开销。
- 时钟(Clock)（近似LRU）给每一页框管理一个附加位（使用位）。使用过置为1，需要置换一页时，查找0位置换，找不到就把所有都置为0，再回到初始位置置换。

### 写时复制

- 原理：创建子进程的时候，将父进程的虚拟内存和物理内存映射关系复制到子进程中，
并将内存设置为只读（为了当对内存进行写操作时触发缺页异常）。
当子进程或者父进程对内存数据进行修改时，
便会触发写时复制的功能，将原来的内存页复制一份新的，
并重新设置其内存映射关系，将父子进程的内存读写设置为读和写。
*只有当任一进程尝试修改内存页时，该内存页才会被复制，每个进程拥有独立的副本。*


### 操作系统中的缺页中断是什么？
- malloc()和mmap()等内存分配函数，在分配时只是建立了进程虚拟地址空间，并没有分配虚拟内存对应的物理内存。当进程
访问这些没有建立映射关系的虚拟内存时，处理器自动触发一个缺页异常。

- 在请求分页系统中，可以通过查询页表中的状态位来确定所访问的页面是否存在于内存中。每当索要访问的页面不在内存时，会产生一次**缺页中断**，此时操作系统会根据页表中的外存地址在外存中找到所缺的一页，将其调入内存。

- 缺页本身是一种中断：
  1. 保护CPU现场
  2. 分析中断原因
  3. **转入缺页中断处理程序进行处理**
  4. 恢复CPU现场，继续执行

  是硬件所产生的一种特殊的中断。
  
### 为什么要有page cache，操作系统怎么设计的page cache？
- 加快从磁盘读取文件的速率。
- 减少 I/O 次数，提高系统磁盘 I/O 吞吐量
- 缺点
  - 需要占用额外物理内存空间，物理内存在比较紧俏的时候可能会导致频繁的 swap 操作，最终导致系统的磁盘 I/O 负载的上升。
  - 对应用层并没有提供很好的管理 API，几乎是透明管理。应用层即使想优化 Page Cache 的使用策略也很难进行。因此一些应用选择在用户空间实现自己的 page 管理，而不使用 page cache，例如 MySQL InnoDB 存储引擎以 16KB 的页进行管理。
  - 在某些应用场景下比 Direct I/O 多一次磁盘读 I/O 以及磁盘写 I/O。


### malloc 是如何分配内存的？
- 方式一：通过 brk() 系统调用从堆分配内存
  - 通过 brk() 函数将「堆顶」指针向高地址移动，获得新的内存空间
- 方式二：通过 mmap() 系统调用在文件映射区域分配内存
  - 通过 mmap() 系统调用中「私有匿名映射」的方式，在文件映射区分配一块内存。
- 如果用户分配的内存小于 128 KB，则通过 brk() 申请内存；
- 如果用户分配的内存大于 128 KB，则通过 mmap() 申请内存；
- malloc() 在分配内存的时候，并不是老老实实按用户预期申请的字节数来分配内存空间大小，
  而是**会预分配更大的空间作为内存池**。
### malloc() 分配的是物理内存吗？
- 不是的，malloc() 分配的是虚拟内存。
### malloc 申请的内存，free 释放内存会归还给操作系统吗？
- malloc 通过 brk() 方式申请的内存，free 释放内存的时候，**并不会把内存归还给操作系统，而是缓存在 malloc 的内存池中，待下次使用**
- malloc 通过 mmap() 方式申请的内存，free 释放内存的时候，**会把内存归还给操作系统，内存得到真正的释放**
### free() 函数只传入一个内存地址，为什么能知道要释放多大的内存？
- alloc 返回给用户态的内存起始地址比进程的堆空间起始地址多了 16 字节，16 字节就是保存了该内存块的描述信息，比如有该内存块的大小。
这样当执行 free() 函数时，free 会对传入进来的内存地址向左偏移 16 字节，然后从这个 16 字节的分析出当前的内存块的大小，自然就知道要释放多大的内存了。

## 内存满了，会发生什么？
- 没有空闲的物理内存，那么内核就会开始进行回收内存的工作，回收的方式主要是两种：直接内存回收和后台内存回收。
  - **后台内存回收（kswapd）**：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程**异步**的，不会阻塞进程的执行。
  - **直接内存回收（direct reclaim）**：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是**同步**的，会阻塞进程的执行。
  - 回收后，空闲的物理内存仍然无法满足此次物理内存的申请，则触发**OOM(Out of Memory)机制**
    - OOM Killer 机制会根据算法选择一个占用物理内存较高的进程，然后将其杀死，以便释放内存资源，依然不足则继续杀死高内存进程
### 哪些内存可以回收？
- 文件页（File-backed Page）：内核缓存的磁盘数据（Buffer）和内核缓存的文件数据（Cache）都叫作文件页。
  - 回收**干净页**的方式是**直接释放内存**，回收**脏页**的方式是**先写回磁盘后再释放内存**。
- 匿名页（Anonymous Page）：这部分内存没有实际载体，如堆、栈数据等。这部分内存可能会被再次访问，
  - **通过Linux 的Swap机制** —— 把不常访问的内存先写到磁盘中，然后释放内存给其他需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。
- 文件页和匿名页的回收都是基于 LRU 算法，也就是优先回收不常访问的内存。
   LRU 回收算法，实际上**维护着 active 和 inactive 两个双向链表**
   
### 回收内存带来的影响
- 涉及磁盘I/O操作都会影响性能
### 什么条件下才能触发 kswapd 内核线程(异步，后台回收)回收内存呢？
- 内核定义了三个内存阈值（watermark，也称为水位），用来衡量当前剩余内存（pages_free）是否充裕或者紧张，分别是：
  -	页最小阈值（pages_min）
  -	页低阈值（pages_low）  **触发 kswapd 异步不阻塞**
  -	页高阈值（pages_high） **触发直接内存回收 同步阻塞**
  
  
### NUMA 架构下的内存回收策略
- 非一致存储访问结构（Non-uniform memory access，NUMA）
- NUMA 架构将每个 CPU 进行了分组，每一组 CPU 用 Node 来表示，一个 Node 可能包含多个 CPU 。
- **每个 Node 有自己独立的资源，包括内存、IO 等**
- 在 NUMA 架构下，当某个 Node 内存不足时，系统可以从其他 Node 寻找空闲内存，也可以从本地内存中回收内存。
### 如何保护一个进程不被 OOM 杀掉呢？
- 调整该进程的 oom_score_adj，从而改变这个进程的得分结果，降低该进程被 OOM 杀死的概率。
- 如果你想某个进程无论如何都不能被杀掉，那你可以将 oom_score_adj 配置为 -1000。

### 在 4GB 物理内存的机器上，申请 8G 内存会怎么样？
- 32 位操作系统，进程最多只能申请 3 GB 大小的虚拟内存空间，所以进程申请 8GB 内存的话，在申请虚拟内存阶段就会失败
- 64 位操作系统，进程可以使用 128 TB 大小的虚拟内存空间，所以进程申请 8GB 内存是没问题的，因为进程申请内存是申请虚拟内存，只要不读写这个虚拟内存，操作系统就不会分配物理内存。

### Swap 机制
- Swap 就是把一块磁盘空间或者本地文件，当成内存来使用，它包含换出和换入两个过程：

  - 换出（Swap Out） ，是把进程暂时不用的内存数据存储到磁盘中，并释放这些数据占用的内存；
  - 换入（Swap In），是在进程再次访问这些内存的时候，把它们从磁盘读到内存中来；
- **触发场景**
    - 内存不足
	- 内存闲置
- 作用
   - 如果没有 Swap 分区，因为物理空间不够，进程会被操作系统杀掉，原因是 OOM（内存溢出）；
   - 如果有 Swap 分区，即使物理内存只有 4GB，程序也能正常使用 8GB 的内存，进程可以正常运行

### 如何避免预读失效和缓存污染的问题？(如何改进 LRU 算法)
- 实现方式
  - LRU 算法一般是用「链表」作为数据结构来实现的，链表头部的数据是最近使用的，而链表末尾的数据是最久没被使用的。那么，当空间不够了，就淘汰最久没被使用的节点，也就是链表末尾的数据，从而腾出内存空间。
  
- **传统LRU算法的缺陷**
    - 预读失效导致缓存命中率下降
	- 缓存污染导致缓存命中率下降
- **预读机制**
    - 程序只想读取磁盘上文件 A 的 offset 为 0-3KB 范围内的数据，由于磁盘的基本读写单位为 block（4KB），
	于是操作系统至少会读 0-4KB 的内容，这恰好可以在一个 page 中装下。
    - 操作系统出于空间局部性原理（靠近当前被访问数据的数据，在未来很大概率会被访问到），会选择将磁盘块 offset
	[ [4KB,8KB)、[8KB,12KB) 以及 [12KB,16KB) ]都加载到内存，于是额外在内存中申请了 3 个 page
    - **预读失效**
	    - 被多加载进来的页没有被访问。不会被访问的预读页占用了LRU链表前排位置
		，末尾的淘汰页可能是热点数据，大大降低了缓存命中率。
	- **如何避免预读失效造成的影响**
	    - 让预读页停留在内存里的时间尽可能短，让真正被访问的页移动到LRU链表的头部
		，从而保证热数据留在内存时间尽可能长。
	    - **解决方式**
		    - Linux 操作系统实现**两个了 LRU 链表**：活跃 LRU 链表（active_list）和非活跃 LRU 链表（inactive_list）。
			- MySQL 的 Innodb 存储引擎是在**一个 LRU 链表**上划分来 2 个区域，young 区域 和 old 区域。

- ** 缓存污染**
     - 只被读取一次的页就放入young区或活跃区，把热点数据都挤到了old区、非活跃区或挤出了缓存页，然而被访问一次的数据后续就没有被访问过，访问热点数据又要进行I/O磁盘操作。
     - **怎么避免缓存污染造成的影响？**
	     - 提高进入到活跃 LRU 链表（或者 young 区域）的门槛，就能有效地保证活跃 LRU 链表（或者 young 区域）里的热点数据不会被轻易替换掉。
		 - Linux 操作系统：在内存页被访问第二次的时候，才将页从 inactive list 升级到 active list 里。
		 - MySQL Innodb：在内存页被访问第二次的时候，并不会马上将该页从 old 区域升级到 young 区域，因为还要进行停留在 old 区域的时间判断：
		   - 如果第二次的访问时间与第一次访问的时间在 1 秒内（默认值），那么该页就不会被从 old 区域升级到 young 区域；
           - 如果第二次的访问时间与第一次访问的时间超过 1 秒，那么该页就会从 old 区域升级到 young 区域；



## 深入理解Linux虚拟内存管理
### fork() vfork()/clone()
- 通过 fork() 函数创建出的子进程，它的虚拟内存空间以及相关页表相当于父进程虚拟内存空间的一份**拷贝**，直接从父进程中拷贝到子进程中。
- 通过 vfork 或者 clone 系统调用创建出的子进程，首先会设置 CLONE_VM 标识，这样来到 copy_mm 函数中就会进入 if (clone_flags & CLONE_VM) 条件中，在这个分支中会将父进程的虚拟内存空间以及相关页表直接赋值给子进程。这样一来**父进程和子进程的虚拟内存空间就变成共享**的了。
   也就是说父子进程之间使用的虚拟内存空间是一样的，并不是一份拷贝。
- **是否共享地址空间**几乎是**进程和线程**之间的**本质区别**。Linux 内核并不区别对待它们，线程对于内核来说仅仅是一个共享特定资源的进程而已。
- **内核线程和用户态线程**的区别就是内核线程没有相关的内存描述符 mm_struct ，内核线程对应的 task_struct 结构中的 mm 域指向 Null，所以内核线程之间调度是不涉及地址空间切换的。


## 进程调度/页面置换/磁盘调度算法

### 进程调度
- 多级反馈队列调度算法
  -  是「时间片轮转算法」和「最高优先级算法」的综合和发展。

### 页面置换

### 磁盘调度算法
- 先来先服务算法
- 最短寻道时间优先算法
  - 找离磁头最近的位置
- 扫描算法
  - 在一个方向上移动，访问所有未完成的请求，
  直到磁头到达该方向上的最后的磁道，才调换方向
- 循环扫描算法
  - 磁头到次到「尾端或者首端」
- LOOK 与 C-LOOK 算法  
  - 磁头只到「最远的请求」位置

## 文件管理系统

### 文件I/O
- 缓冲与非缓冲I/O
- 直接与非直接I/O
- 阻塞与非阻塞I/O VS 同步与异步I/O
  - 对于磁盘，异步I/O只支持直接I/O，直接I/O会绕开PageCache
  - 大文件的传输不应该使用 PageCache，因为可能由于 PageCache 被大文件占据，而导致「热点」小文件无法利用到 PageCache。
  - **在高并发的场景下，针对大文件的传输的方式，应该使用「异步 I/O + 直接 I/O」来替代零拷贝技术。**
  
### 进程写文件时，进程发生了崩溃，已写入的数据会丢失吗？
- 不会。进程在执行 write （使用缓冲 IO）系统调用的时候，实际上是将文件数据写到了内核的 page cache，它是文件系统中用于缓存文件数据的缓冲，所以即使进程崩溃了，文件数据还是保留在内核的 page cache，我们读数据的时候，也是从内核的 page cache 读取，因此还是依然读的进程崩溃前写入的数据。
内核会找个合适的时机，将 page cache 中的数据持久化到磁盘。但是如果 page cache 里的文件数据，在持久化到磁盘化到磁盘之前，系统发生了崩溃，那这部分数据就会丢失了。
当然， 我们也可以在程序里调用 fsync 函数，在写文文件的时候，立刻将文件数据持久化到磁盘，这样就可以解决系统崩溃导致的文件数据丢失的问题。

## 设备管理

### 存储系统 I/O 软件分层
- 文件系统层，包括虚拟文件系统和其他文件系统的具体实现，它向上为应用程序统一提供了标准的文件访问接口，向下会通过通用块层来存储和管理磁盘数据。
- 通用块层，包括块设备的 I/O 队列和 I/O 调度器，它会对文件系统的 I/O 请求进行排队，再通过 I/O 调度器，选择一个 I/O 发给下一层的设备层。
- 设备层，包括硬件设备、设备控制器和驱动程序，负责最终物理设备的 I/O 操作。

- 设备 > PC ：： **设备驱动程序** > 外部设备 > 中断控制器 > CPU > **进程** > 保存上下文 > 调用对应的中断处理函数 > 中断处理函数（**设备驱动程序**）> 中断处理 > 恢复上下文 > **进程**


# 网络系统
## 什么是 直接内存访问（DMA Direct Memory Access） 技术？
  - 在进行 I/O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务。
  
  - 具体过程
    - CPU全程参与
	
	  用户进程 > CPU > 磁盘
	  
	- CPU只参与首位
	
	  用户进程 > CPU > DMA > 磁盘
	  
- 要想提高文件传输的性能，就需要减少「用户态与内核态的上下文切换」和「内存拷贝」的次数。
  - 要想减少上下文切换到次数，就要减少系统调用的次数。
  - 用户的缓冲区是没必要存在的（内核到用户的内存拷贝）
  
## 如何实现零拷贝？
- mmap + write
	```
	{
		buf = mmap(file, len);
		write(sockfd, buf, len);
	}
	```
    - mmap() 系统调用函数会直接把内核缓冲区里的数据「映射」到用户空间，这样，操作系统内核与用户空间就不需要再进行任何的数据拷贝操作。
	  - 应用进程调用了 mmap() 后，DMA 会把磁盘的数据拷贝到内核的缓冲区里。
	  - 接着，应用进程跟操作系统内核「共享」这个缓冲区；
	  - 应用进程再调用 write()，操作系统直接将内核缓冲区的数据拷贝到 socket 缓冲区中，这一切都发生在内核态，由 CPU 来搬运数据；
	  - 最后，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程是由 DMA 搬运的。
      - 我们可以得知，通过使用 mmap() 来代替 read()， 可以减少一次数据拷贝的过程。但这还不是最理想的零拷贝，因为仍然需要通过 CPU 把内核缓冲区的数据拷贝到 socket 缓冲区里，而且仍然需要 4 次上下文切换，因为系统调用还是 2 次。
- sendfile
	```
	{
		#include <sys/socket.h>
		ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);
	}
	```
	首先，它可以替代前面的 read() 和 write() 这两个系统调用，这样就可以减少一次系统调用，也就减少了 2 次上下文切换的开销。
	其次，该系统调用，可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态，这样就只有 2 次上下文切换，和 3 次数据拷贝。
	
- sendfile  **SG-DMA**（The Scatter-Gather Direct Memory Access）
   - 第一步，通过 DMA 将磁盘上的数据拷贝到内核缓冲区里；
   - 第二步，缓冲区描述符和数据长度传到 socket 缓冲区，这样网卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里，此过程不需要将数据从操作系统内核缓冲区拷贝到 socket 缓冲区中，这样就减少了一次数据拷贝；
   - 只进行了 2 次数据拷贝。
   - **这就是所谓的零拷贝（Zero-copy）技术，因为我们没有在内存层面去拷贝数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的。**
   - 传输大文件的时候，使用「异步 I/O + 直接 I/O」；
传输小文件的时候，则使用「零拷贝技术」；

## I/O多路复用
### epoll
- epoll 在内核里使用**红黑树**来跟踪进程所有待检测的文件描述字,只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。
- epoll 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 socket 有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，
 当用户调用 epoll_wait() 函数时，只会返回有事件发生的文件描述符的个数，不需要像 select/poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。
- epoll 支持两种事件触发模式，分别是边缘触发（edge-triggered，ET）和水平触发（level-triggered，LT）。
	- 使用**边缘触发模式**时，当被监控的 Socket 描述符上有可读事件发生时，服务器端只会从 epoll_wait 中苏醒一次，即使进程没有调用 read 函数从内核读取数据，也依然只苏醒一次，
	   因此我们程序要保证一次性将内核缓冲区的数据读取完；**边缘触发模式一般和非阻塞 I/O 搭配使用**
	- 使用**水平触发模式**时，当被监控的 Socket 上有可读事件发生时，服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束，目的是告诉我们有数据需要读取；

## 高性能网络模式：Reactor 和 Proactor
### Reactor 模式
- 即 I/O 多路复用监听事件，收到事件后，根据事件类型分配（Dispatch）给某个进程 / 线程。
  **是非阻塞同步网络模式**，感知的是就绪可读写事件。在每次感知到有事件发生（比如可读就绪事件）后，就需要应用进程主动调用 read 方法来完成数据的读取，也就是要应用进程主动将 socket 接收缓存中的数据读到应用进程内存中，这个过程是同步的，读取完数据后应用进程才能处理数据。
### Proactor 模式
- **异步网络模式**， 感知的是已完成的读写事件。在发起异步读写请求时，需要传入数据缓冲区的地址（用来存放结果数据）等信息，这样系统内核才可以自动帮我们把数据的读写工作完成，这里的读写工作全程由操作系统来做，并不需要像 Reactor 那样还需要应用进程主动发起 read/write 来读写数据，操作系统完成读写工作后，就会通知应用进程直接处理数据。

## 一致性哈希
- 一致性哈希算法就很好地解决了**分布式系统**在扩容或者缩容时，发生过多的**数据迁移**的问题。
- 哈希算法是对节点的数量进行取模运算，而**一致哈希算法是对 2^32 进行取模运算，是一个固定的值**。
- **将「存储节点」和「数据」都映射到一个首尾相连的哈希环上**
### 对「数据」进行哈希映射得到一个结果要怎么找到存储该数据的节点呢？
- 顺时针的方向的找到第一个节点（存储服务器）
-寻找存储的数据
  - 首先，对 key 进行哈希计算，确定此 key 在环上的位置；
  - 然后，从这个位置沿着顺时针方向走，遇到的第一节点就是存储 key 的节点。

- **√** 在一致哈希算法中，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响。
- X 一致性哈希算法虽然减少了数据迁移量，但是存在节点分布不均匀的问题

### 如何通过虚拟节点提高均衡度？
- **不再将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点，所以这里有「两层」映射关系。**
- **虚拟节点**除了会提高节点的均衡度，还会提高系统的稳定性。当节点变化时，会有不同的节点共同分担系统的变化，因此稳定性更高。
- 带虚拟节点的一致性哈希方法不仅**适合硬件配置不同的节点的场景**（为硬件配置更好的节点增加权重，比如对权重更高的节点增加更多的虚拟机节点即可），而且**适合节点规模会发生变化的场景**。


# 刷题记录
- 49 <https://leetcode.cn/problems/group-anagrams/description/>
  - 需要根据特征进行归类时，应使用散列表。
  ```
	
		vector<vector<string>> groupAnagrams(vector<string>& strs) {
			unordered_map<string, vector<string>> mp;
			for (string& str: strs) {
				string key = str;
				sort(key.begin(), key.end());
				mp[key].emplace_back(str);
			}
			vector<vector<string>> ans;
			for (auto it = mp.begin(); it != mp.end(); ++it) {
				ans.emplace_back(it->second);
			}
			return ans;
		}
	
	```
- 75 冒泡排序 <https://leetcode.cn/problems/sort-colors/description/>
- 148 排序链表 <https://leetcode.cn/problems/sort-list/description/>
- 归并排序

- 21 合并两个有序链表 <https://leetcode.cn/problems/merge-two-sorted-lists/description/> 迭代法。
- 无序列表排序 、 有序列表合并 、 无序列表合并
- 86 分隔列表 <https://leetcode.cn/problems/partition-list/submissions/534868520/>
     - 将一条链表分成两条时，推进cur顺序节点时要断开原链表中的每个节点的 next 指针
     ```
		 ListNode *temp = p->next;
		 p->next = NULL;
		 p = temp;
	 ```
- 1457 如果一组数字中，只有最多一个数字出现的次数为奇数，剩余数字的出现次数均为偶数，那么这组数字可以组成一个回文串。	

- 优先级队列
	- Lambda 表达式 重定义队列  
	   - '>' 小顶堆 最顶层最小
	   - '<' 大顶堆 最顶层最大
	```
		priority_queue<pair<int,int>, vector<pair<int,int>>, function<bool(pair<int,int>,pair<int,int>)>> pq(
            [] (pair<int,int> a, pair<int,int> b){return (a.first+a.second) < (b.first+b.second);});
	```
	
- 二分查找法  ***普通 左边界 右边界***
	```
		int binary_search(vector<int>& nums, int target) {
			int left = 0, right = nums.size()-1; 
			while(left <= right) {
				int mid = left + (right - left) / 2;
				if (nums[mid] < target) {
					left = mid + 1;
				} else if (nums[mid] > target) {
					right = mid - 1; 
				} else if(nums[mid] == target) {
					// 直接返回
					return mid;
				}
			}
			// 直接返回
			return -1;
		}

		int left_bound(vector<int>& nums, int target) {
			int left = 0, right = nums.size()-1;
			while (left <= right) {
				int mid = left + (right - left) / 2;
				if (nums[mid] < target) {
					left = mid + 1;
				} else if (nums[mid] > target) {
					right = mid - 1;
				} else if (nums[mid] == target) {
					// 别返回，锁定左侧边界
					right = mid - 1;
				}
			}
			// 判断 target 是否存在于 nums 中
			if (left < 0 || left >= nums.size()) {
				return -1;
			}
			// 判断一下 nums[left] 是不是 target
			return nums[left] == target ? left : -1;
		}

		int right_bound(vector<int>& nums, int target) {
			int left = 0, right = nums.size()-1;
			while (left <= right) {
				int mid = left + (right - left) / 2;
				if (nums[mid] < target) {
					left = mid + 1;
				} else if (nums[mid] > target) {
					right = mid - 1;
				} else if (nums[mid] == target) {
					// 别返回，锁定右侧边界
					left = mid + 1;
				}
			}

			// 由于 while 的结束条件是 right == left - 1，且现在在求右边界
			// 所以用 right 替代 left - 1 更好记
			if (right < 0 || right >= nums.size()) {
				return -1;
			}
			return nums[right] == target ? right : -1;
		}

	```


- 快速得到 k 个节点中的最小节点> **优先级队列（二叉堆）**[把链表节点放入一个最小堆，就可以每次获得 k 个节点中的最小节点]
- 丑数、大顶堆、小顶堆
- BST二叉搜索树的**中序遍历特性**：从小到大的有序数列。


- 1438<https://leetcode.cn/problems/longest-continuous-subarray-with-absolute-diff-less-than-or-equal-to-limit/>
  ```
		class Solution {
		public:
			int longestSubarray(vector<int>& nums, int limit) {
				multiset<int> st;
				int left = 0, right = 0;
				int res = 0;
				while (right < nums.size()) {
					st.insert(nums[right]);
					while (*st.rbegin() - *st.begin() > limit) {
						st.erase(st.find(nums[left]));
						left ++;
					}
					res = max(res, right - left + 1);
					right ++;
				}
				return res;
			}
		};

  ```
  - multiset的用法 
	- multiset 是一个基于红黑树实现的有序容器(平衡二叉搜索树)，它会自动将插入的元素按照键值排序。
    - begin() 返回指向第一个元素的迭代器。**最小**
	- rbegin() 返回指向最后一个元素的逆向迭代器。**最大**
	- st.find(val)
	- st.erase(val)

# C++

## 库

### 静态库
- 生成编译文件.o: gcc -c x.c xx.c -I /include[路劲里面包含.h头文件] ：生成*.o **.o 
- 生成静态库.a：ar rcs libxxx.a x.o xx.o ……     xxx：库的名称
- 使用静态库：gcc main.c -o app -I include/ -L lib/ -l xxx
- GCC链接时，静态库的代码会打包到可执行程序中。
### 动态库
- 生成编译文件.o：gcc -c -fpic x.c xx.c
- 生成动态库.so：gcc -shared x.o xx.o -o libxxx.so
- 使用动态库：gcc main.c -o app -I include/ -L lib/ -l xxx
- GCC链接时，动态库的代码不会打包到可执行程序中。
## 重载 重写

### 重载
- 一个方法有不同的版本，存在于一个类中。
- void print（int x） void print(double x)……
### 重写
- 指派生类（子类）中的成员函数重新定义了基类（父类）中的虚函数（virtual function）
	```
		class Base {//基类
		public:
			virtual void display() {
				std::cout << "Base display" << std::endl;
			} 
		};

		class Derived : public Base {//重写
		public:
			void display() override { // 使用override关键字可以明确指出这是一个重写
				std::cout << "Derived display" << std::endl;
			}
		};
	```
### 虚函数表以及多态
- 虚函数指针vtpr
- 虚函数表vtbl
- 实现多态的三个条件
  - 存在继承关系 子类继承父类
  - 子类重写父类的virtual function
  - 子类以父类的指针或者是引用的身份出现

## new malloc
- malloc与free是C++/C语⾔的标准库函数,new/delete是C++的运算符 
- new（不用指定分配大小）操作符从自由存储区上为对象动态分配内存空间，而malloc（需要指定分配大小）函数从堆上动态分配内存

## const constexpr volatile


## std::atomic

## map set
- 同
	- 都是关联容器，底层都是采用红黑树实现。10
- 不同
	- ***set*** 用来判断一个元素是不是在一个组里面。
	- ***map*** 映射，相当于字典
	
## 友元函数 关键字：friend
- 可以访问类内的私有成员。

## 智能指针
- share_ptr
- make_share
  - share_ptr<int> a = make_share<int>(10)
  - share_ptr<class> a = make_share<class>(10)
  - |new int(10) | uses | weaks|  => 同时创建
  - 优点：内存分配效率高，防止资源泄露的风险
  - 缺点：make_share无法自定义删除器，导致托管的资源延迟释放
- weak_ptr
  - 强智能指针引用计数器观察者，使用lock提升为强智能指针操作资源
- unique_ptr
- make_unique


## this指针
- this指针是类的指针，指向对象的首地址，不占用类的大小
- 指针只能在成员函数中使用，全局函数、静态成员函数不能使用this
  - 静态成员函数是先于对象存在的，是所有对象共有的，因此不会有this指针
- this指针只有在成员函数中才有定义，且存储位置会因编译器不同有不同存储位置。
- this指针创建时间：成员函数开始执行前构造，成员执行结束后删除
- this指针存放位置，会因为编译器的不同有不同的放置位置，可能是在栈、寄存器或者全局变量

## STL六大部件
- 容器、分配器、适配器、迭代器、算法、仿函数

## 模式

### 代理模式
- 通过代理类，来控制实际对象的访问权限 [ 抽象类 委托类 ]
### 单例模式
- 一个类不管创建多少次对象，永远只能得到该类型一个对象的实例
- 常用到的，比如日志模块，数据库模块
- 具体操作：
   1. 构造函数私有化 private: ……
   2. 定义一个唯一的类的实例对象 [静态]
   3. 获取类的唯一实例对象的接口方法 public：……
   4. **删除拷贝构造函数和拷贝赋值运算符**
- 懒汉单例模式 线程不安全，要加锁，加volatile
- 饿汉单例模式 线程一定安全
### 工厂模式
- 主要是封装了对象的创建
#### 简单工厂
- 把对象的创建封装在一个接口函数里面，通过传入不同的标识，返回创建的对象客户不用自己
负责new对象， 不用了解对象创建的详细过程。

- 但， 提供创建对象实例的接口函数不闭合，不能对修改关闭
#### 工厂方法
- 创建工厂基类 各类产品厂继承工厂基类  要符合开闭原则
- Factory基类，提供了一个纯虚函数（创建产品），定义派生类（具体产品的工厂）负责创建对应的产品，可以做到不同的产品在不同的工厂里面创建，能够对现有工厂以及产品的修改关闭。
- 但， 实际上，很多产品是有关联关系的，属于一个产品蔟，不应该放在不同的工厂里面去创建，一是不符合实际的产品对象创建逻辑，二是工厂类太多了，不好维护
#### 抽象工厂
- 对有一组关联关系的产品蔟提供产品对象的统一创建

### 装饰器模式
- 主要是增加现有类的功能 ， 但是 ，增加现有类的功能还有一个方法是新增加一个子类（添加太多了）

### 观察者模式/观察者-监听者模式/发布-订阅模式
- 行为型模式：主要关注的是对象之间的通信
- 主要关注的是对象的一对多的关系，也就是多个对象都依赖一个对象，当该对象的状态发生改变时，
其他对象都能够接收到相应的通知。

### 适配器模式
- 让不兼容的接口可以在一起工作


# 面经
- C++this指针干什么用的？
  - 一个类定义的多个对象都有自己的成员变量，共享一套方法，当对象调用方法
  ，方法该如何知道调用的是哪个成员，就是通过this指针来区分。
  
- C++的static关键字的作用？
  - 从面向过程：static可以修饰全局变量、函数 =》被修饰后，从符号表中作用域从g变为l；修饰局部变量=》将被放入.data 或 .bss 产生符号
  
  - 从面向对象：static可以修饰成员变量、成员方法 =》 对象私有变成对象共享，成员方法不再产生this指针，不需要通过对象调用，直接可以通过类作用域调用
  
- C++继承
  - 代码的复用、多态

- C++的继承多态、空间配置器、vector 和 list 的区别， map， 多重map？
  - 多态：
    - 静多态：编译时期，编译器会根据实参类型来选择调用合适的函数[函数模板 函数重载]
	- 动多态：运行时期，虚函数 指针/引用指向派生类(子类)对象，需要满足三个条件。
	
  - 空间配置器allocator：
    - 用于管理内存分配和释放的组件
	- 给容器使用，把内存开辟和对象构造分开，把对象析构和内存释放分开
  - vector list:
    - vector做随机访问多（优先级队列基于vector） 内存连续 两倍扩增
	- list 增加删除操作多O(1) 内存不连续 双向链表
  - map: 映射表，底层实现为红黑树，不允许key重复 | multimap 允许key重复
  - set：只存key，底层实现为红黑树
  - deque：二维动态数组
  - 红黑树：
	- 五个性质
	- 插入的三种情况
	- 删除的四种情况
- 什么是内存泄漏？如何防止内存泄露？智能指针详述？检查内存泄露的方法？
  - 内存泄漏：
	- 分配的堆内存没有释放，也再没有计会释放
  - 智能指针：
    - 引用计数器？线程是否安全？
	- share_ptr引用计数存在哪里？ 堆上分配<https://blog.csdn.net/QIANGWEIYUAN/article/details/88973735?spm=1001.2014.3001.5501>
  - 检查内存泄露 使用 **valgrind**工具
  
  
- C++什么时候会出现访问越界？
  1. 访问数组元素越界
  2. vector容器访问
  3. ……
  4. 访问超过系统分配的内存
  5. 字符串处理，没有添加“\0”
  6. 使用类型强转，让一个大类型的指针指向一块小内存，然后指针解引用，访问的内存就越界了
  
- C++初始化列表
  
  1. 效率：对于内置类型或没有默认构造函数的对象，初始化列表可以直接在内存中初始化成员，而不需要调用默认构造函数。
  2. 必要性：对于常量成员变量和引用成员变量，必须使用初始化列表进行初始化，因为它们不能在构造函数体中被赋值。
  3. 清晰性：初始化列表提供了一个清晰的方式来显示哪些成员被初始化以及它们的初始值。
  4. 顺序：成员变量在初始化列表中的顺序必须与它们在类声明中的声明顺序相同。
  
- malloc new
  - malloc按字节开辟内存 | 开辟失败返回nullptr | C的库函数  | brk(堆) < (128k) < mmap(文件映射区) 
  
  - new底层是通过malloc开辟内存，还可以提供初始化 | 开辟失败，抛出bad_alloc类型的异常 | operator new
  
- 函数对象
  - 通常通过重载operator()来实现，这样它们就可以接受参数并返回值
  - 函数对象可以是普通的类类型，也可以是Lambda表达式
  
- STL中的迭代器失效的问题
  - 迭代器是不允许一边读一边修改的
  - 当通过迭代器插入一个元素，所有迭代器就都失效了
  - 当通过迭代器删除一个元素，当前删除位置的后面所有元素的迭代器就都失效了
  - 当通过迭代器更新容器元素以后，要及时堆迭代器进行更新，insert/erase方法都会返回新位置的迭代器

- 编译链接全过程？
  - 预编译
  - 编译
  - 汇编 =》 二进制可重定位obj文件
  - 链接
    - 合并段，符号解析 =》 符号重定向 =》 可执行文件
	
- 堆栈 区别
  - 堆 =》 低地址 =》高地址 malloc/new  free/delete
  - 栈 =》 高地址 =》低地址 函数的局部变量 会自动释放
  
- 构造函数和析构函数可不可以是虚函数？
  - 构造函数不能是虚函数，在构造函数中是不会进行动态绑定的。
  - 析构函数可以是虚函数，并且在实现多态的时候是非常有必要设置为虚析构函数，否则通过基类指针调用派生类后要delete，只能调用基类的析构函数，无法调用派生类的析构函数


- 构造函数和析构函数中能不能抛出异常？
  - 构造函数不能抛出异常，对象创建失败，就不会调用对象的析构函数了，造成内存泄漏，可以使用智能指针解决问题。
  - 析构函数不能抛出异常，后面的代码就无法得到执行了

- 宏和内联函数的区别  

- 拷贝构造函数，为什么传引用而不传值
  - 传值会产生编译错误
  - 提高性能、避免递归调用，并减少不必要的内存消耗
  
- **内联函数**和普通函数的区别（从反汇编角度回答）
  - 函数的调用开销
  - 在编译过程中，就没有函数的调用开销，在函数的调用点直接把函数的代码进行展开处理了
  - inline函数不再生成相应的函数符号
  
- 如何实现一个不可以被继承的类？
  - 派生类的初始化过程：基类构造 =》派生类构造  | 基类的构造函数私有化

- 什么是纯虚函数？
  - virtual void func()=0; 纯虚函数 =》 抽象类 （不能实例化对象的， 可以定义指针和引用）
- 为什么要有纯虚函数？
  - 一般定义在基类里面，基类不代表任务实体，他的主要作用之一就是给所有的派生类保留统一的纯虚函数接口，
让派生类进行重写，方便的使用多态机制。基类不需要实例化。  
- 虚函数表放在哪里？
  - 虚函数表在编译阶段产生，运行时加载到.rodata段
  
- C++中的const以及与static的区别
  - const定义的叫常量， 他的编译方式是：编译过程中，把出现常量名字的地方，用常量的值进行替换
  ```
	const int b = 10 //编译器会将这个常量存储在程序的只读数据段（通常是.rodata段）中。运行时会将b直接替换成10
	int* p = (int*)&b;
    *p = 20;
    cout << b << "|||" << *p << endl;//b = 10 *p = 20
    cout << &b << "|||" << p << endl;//地址相同
  ```
  - const还可以定义常成员方法，Test *this =》 const Test *this ，在方法内，不能使用this->成员参数
  - const 和 static 的区别
	- 面向过程
      - const：全局变量、局部变量、形参变量 不能修饰函数
	  - static：全局变量、局部变量、函数
	- 面向对象
	  - const：常方法/成员变量    =》Test *this -> const Test *this 依赖对象
	  - static：静态方法/成员变量 =》Test *this -> 没有了，不依赖对象
	  
- 四种强制类型转换？

- 详细解释deque的底层原理

  - 动态开辟的二维数组
  - #define MAP_SIZE 2
  - #define QUE_SIZE(T) 4096/sizeof(T)
  
  - 一维数组的初始大小为 MAP_SIZE(T*)
  - 第二维数组默认开辟的大小就是QUE_SIZE(int) 1024 
  - 双端队列 两端都有队头和队尾 两端都可以插入删除 O(1)
  - 扩容：把第一维数组按照两倍的方式进行扩容 2-4-8-16…… 扩容后会把原来的第二维的数组，从新一维数组的第oldsize/2 开始存放
  - 内存利用率好，刚开始就有一段内存可供使用
  
- 虚函数，多态
  - 纯虚函数：virtual void func() = 0;
  - 一个类 =》 虚函数 =》 编译阶段 =》 该类产生一张虚函数表 =》 运行时加载到.rodata段
  - 用指针或者引用调用虚函数，指针访问对象的头四个字节vfptr，从vftable中取虚函数的地址，进行动态绑定调用
  - 多态：设计函数接口的时候， 可以都是用基类的指针或者引用来接收不同的派生类对象，功能增加、删除；在各类设计模式中运用较多
  
- 虚析构函数、智能指针？
  - 是为了防止基类指针无法调用派生类的析构函数，在delete 基类指针时。
  - 智能指针：管理资源的生命周期。
  
- 早绑定、晚绑定
  - 早绑定(静态绑定)：普通函数的调用，用对象调用虚函数  call编译阶段已经知道调用哪个函数
  
  - 晚绑定(动态邦定)：用指针/引用调用虚函数的时候，都是动态绑定 p-> vfprt-> vftable-> virtual addr=> call eax
- 指针和引用的区别？（反汇编分析）
  - 引用比指针安全：指针不一定要初始化 ， 引用一定要初始化。
  - 汇编中产生的代码是一样的
  ```
	int a =10;
	int *p = &a;
	int &b = a;
	*p =20;
	b = 20;
  ```

- 智能指针交叉引用  
  - 定义对象的时候用强智能指针shared_ptr, 而引用对象的时候用弱智能指针weak_ptr
  - 当通过weak_ptr访问对象成员时，需要先调用weak_ptr的lock提升方法，把weak_ptr提升成shared_ptr强智能指针，再进行对象成员调用
  
- 重载的底层实现，虚函数的底层实现
  - 重载：因为C++生成函数符号， 是依赖函数名字+参数列表。
  编译到函数调用点时，根据函数名字和传入的实参（个数和类型），和某一个函数重载匹配的话，那么就直接调用相应的函数重载版本（静态的多态 都是在编译阶段处理的）
  
  - 虚函数=》对象  vfptr-> vftable-> 函数地址 => call eax
  
- 假如map的键时类类型，那么map底层是如何调整的？
  - 红黑树 [key,value]， 默认为 less < key  ， 记得 **operator< 运算符的重载函数**
  
- **如果让你实现一个内存池，要求获取资源和插入资源时间花费O(1)，你会怎么设计？**
  - SGI STL二级空间配置器的内存池的实现就可以了

- **C++语言级别提供的四种类型转换方式**
  - const_cast : 去掉常量属性的一个类型转换
  ```
	const int a = 10;
	int *p1 = const_cast<int*>(&a)
  ```
  - static_cast : 提供编译器认为安全的类型转换（没有任何联系的类型之间的转换就被否定）
  - reinterpret_cast : 类似于C风格的强制类型转换。
  - dynamic_cast : 主要用在继承结构中，可以支持RTTI类型识别的上下转换。（运行时期的类型转换，转换成功返回该类型的指针，失败返回空指针）

- **对象的深拷贝和浅拷贝**和赋值
  - 浅拷贝是对原对象的引用，而不是复制对象本身。新旧对象还是共享同一块内存。 
  - 浅拷贝：对象默认的拷贝构造是直接内存拷贝，对象如果占用外部资源，那么浅拷贝就出现问题了。
  - 浅拷贝可能会**多次调用析构函数**，导致出错。
  - 深拷贝为另外开辟一块内存，将资源拷贝进新内存。
  - 赋值是给变量栈中的内容。
  
- **继承**
  - 公有继承 public
  - 保护继承 protected
  - 私有继承 private
  
  - 对于所有继承方式，基类的私有成员在派生类都是不可见的，不可访问的。
  - 外部只能访问对象public的成员， protected和private的成员无法直接访问。
  - **protected和private的区别**
	- 在基类定义中的成员，想被派生类访问，但是不想被外部访问，可以把相关
       相关成员定义成protected；如果派生类和外部都不打算访问，则设置成private。
  - class  定义派生类，默认方式是 private私有的。
  - struct 定义派生类，默认方式是 public私有的。
  
  - **派生类怎么初始化从基类继承来的成员变量？**
	- 通过调用基类相应的构造函数；
	- 派生类从继承可以继承所有的成员(变量、方法)，除了构造函数和析构函数（但是能调用）。
	- 每类负责自己成员的析构、清理。
  
  - **重载、隐藏、覆盖
	- 重载：一组函数重载，必须处在同一个作用域当中；而且函数名字相同，参数列表不同。
	- 隐藏(作用域的隐藏)：在继承结构体中，派生类的同名成员，吧基类的同名成员给隐藏了(同名即函数名相同)。调用需要加上基类的域名。
	- 覆盖：多态。
  - 派生类对象可以赋给基类对象。反过来不行。
  - 基类指针可以指向派生类对象(多态应用)，只能调用派生类从该基类继承的方法成员。反过来不行。
- **C++多重继承与虚继承**
  - 可以做更多代码的复用
  - 派生类有多份间接基类的代码，即菱形继承
	- 解决：采用虚继承
	
	```
	class A{int ma;} 4字节
	class C{virtual func(); int mc;}
	class B : public A{int mb;}
	
		A::ma 4字节
		mb    4字节
		
	class B : public C{func(); int mb;}
		C::
		  vfptr -> vftable -> C::func()基类的虚函数地址
		  mc		    B::func()派生类的虚函数地址 
		mb			     若派生类基函数有重写将覆盖相应的基类虚函数地址
	
	class B : virtual public A{int mb;}
	
 		vbptr	4字节	虚基类指针->	B::vbtable
		mb				| 0 |起始位
		A::ma				| 8 |偏移量指向A:: 
		
	class B : virtual public C{int mb;}
		
		vbptr
		mb
		C::
		  vfptr   4字节   ->  虚函数指针 -> 虚函数表 vftable
		  mc
	```
  - **基类指针指向派生类（B）,永远指向的是派生类的基类（A|C）部分数据（A::ma|C::func）的起始地址**
  
- **C++11标准**
  - 一 关键字和语法：
    - auto : 可以根据右值的类型，然后左边变量的类型也就已知。
	- nullptr : 给指针专用（能够和整数进行区别）
	- foreach : 可以遍历数组，容器等
		```
			for(Type val : container) =>底层就是通过指针或者迭代器来实现的
			{
				cout << val << ;
			}
		```
	- 右值引用 : move移动语义函数和forward类型完美转发函数[***还未学会***]
	- 模板的新特性
  - 二 绑定器和函数对象 :
    - function : 函数对象 -> 用于保存函数对象返回类型  | function<void()>…… 应用和map结合，可用于实现根据得到的内容实现不同功能的任务
	- bind : 绑定器
  - 三 智能指针 :
    - share_ptr
	- unique_ptr
	- ……
  - 四 容器 :
    - 旧 set | map : 红黑树 o()
    - 新 unordered_set | unordered_map : 哈希表o(1)
  - 五 C++语言级别支持的多线程编程
  
- 
#网络系统面经 
- **sleep(0)的意义**
  - 并非是真的要线程挂起0毫秒，意义在于这次调用Thread.Sleep(0)的当前线程确实的被冻结了一下，让其他线程有机会优先执行。线程暂时放弃cpu，也就是释放-些未用的时间片给其他线程或进程使用，就相当于一个让位动作。
  - 补充：在线程没退出之前，线程有三个状态，就绪态，运行态，等待态。sleep(n)之所以在n秒内不会参与CPU竞争，是因为，当线程调用sleep(n)的时候，线程是由运行态转入等待态，线程被放入等待队列中，等待定时器n秒后的中断事件，当到达n秒计时后，线程才重新由等待态转入就绪态，被放入就绪队列中，**等待队列中的线程是不参与cpu竞争的，只有就绪队列中的线程才会参与cpu竞争**，所谓的cpu调度，就是根据一定的算法(优先级，FIFO等。。。)，从就绪队列中选择一个线程来分配cpu时间。
而sleep(0)之所以马上回去参与cpu竞争，是因为调用sleep(0)后，因为0的原因，线程直接回到就绪队列，而非进入等待队列，只要进入就绪队列，那么它就参与cpu竞争。
  
- **TCP 和 UDP 可以同时绑定相同的端口吗？**
  - 可以。传输层的「端口号」的作用，是为了区分同一个主机上不同应用程序的数据包。
    传输层有两个传输协议分别是 TCP 和 UDP，在内核中是两个完全独立的软件模块。
  - 多个 TCP 服务进程可以同时绑定同一个端口吗？
  - 如何解决服务端重启时，报错“Address already in use”的问题？
    - 对 socket 设置 SO_REUSEADDR 属性。
  - 客户端的端口可以重复使用吗？
  - 客户端 TCP 连接 TIME_WAIT 状态过多，会导致端口资源耗尽而无法建立新的连接吗？
  - 如何解决客户端 TCP 连接 TIME_WAIT 过多，导致无法与同一个服务器建立连接的问题？
    - 打开 net.ipv4.tcp_tw_reuse 这个内核参数。
- TCP三次握手原因
  - 
  - **三次握手才可以阻止重复历史连接的初始化（主要原因）**
  - 三次握手才可以同步双方的初始序列号
  - 三次握手才可以避免资源浪费
  
- 为什么 TCP 每次建立连接时，初始化序列号都要不一样呢？
  - 为了**防止历史报文被下一个相同四元组的连接接收。**
  
  - TCP 四次挥手中的 TIME_WAIT 状态不是会持续 2 MSL 时长，历史报文不是早就在网络中消失了吗？
    - 是的，如果能正常四次挥手，由于 TIME_WAIT 状态会持续 2 MSL 时长，历史报文会在下一个连接之前就会自然消失。
      但是来了，我们并不能保证每次连接都能通过四次挥手来正常关闭连接。
  - 